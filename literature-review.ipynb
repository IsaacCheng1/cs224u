{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae8f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Isaac Cheng\"\n",
    "__purpose__ = \"XCS224U Project Literature Review\"\n",
    "__version__ = \"03/03 2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edb8ea",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Transformer](#Transformer)\n",
    "1. [BERT](#BERT)\n",
    "1. [All The Ways You Can Compress BERT](#All-The-Ways-You-Can-Compress-BERT)\n",
    "1. [Literature Review](#Literature-Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325b77b",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "This section is based on [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56359aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1156124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        \n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65ce21a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7071,  0.7071],\n",
       "        [-0.7071,  0.7071],\n",
       "        [-0.7071,  0.7071]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1, 2], [3, 7], [5, 6]])\n",
    "normLayer = LayerNorm(features=2)\n",
    "normLayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d792a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e5a1ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0245, -0.6093, -0.5761],\n",
       "        [ 0.0000,  0.4098, -2.7355],\n",
       "        [ 0.0000,  0.0000, -0.7653]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "a.triu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8542bd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0245, -0.6093, -0.5761],\n",
       "        [ 0.7395,  0.4098, -2.7355],\n",
       "        [-1.1971, -0.6291, -0.7653]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc4054b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.6093, -0.5761],\n",
       "        [ 0.0000,  0.0000, -2.7355],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c48c586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0245, -0.6093, -0.5761],\n",
       "         [ 0.7395,  0.4098, -2.7355],\n",
       "         [-1.1971, -0.6291, -0.7653]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape((-1, a.shape[0], a.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6d4fe8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.6093, -0.5761],\n",
       "        [ 0.0000,  0.0000, -2.7355],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(a, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2706e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf93b1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subsequent Mask</th>\n",
       "      <th>Window</th>\n",
       "      <th>Masking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subsequent Mask  Window  Masking\n",
       "0             test       0        0\n",
       "0             test       0        1\n",
       "0             test       0        2\n",
       "0             test       0        3\n",
       "0             test       0        4\n",
       "..             ...     ...      ...\n",
       "0             test      19       15\n",
       "0             test      19       16\n",
       "0             test      19       17\n",
       "0             test      19       18\n",
       "0             test      19       19\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "y = 0\n",
    "LS_data = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Subsequent Mask\": [\"test\"],\n",
    "                \"Window\": y,\n",
    "                \"Masking\": x,\n",
    "            }\n",
    "        )\n",
    "        for y in range(20)\n",
    "        for x in range(20)\n",
    "    ]\n",
    ")\n",
    "LS_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ee02f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True],\n",
       "        [False, False]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_mask(2)[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "72ac2487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "subsequent_mask(20)[0][x][y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1f866622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_mask(20)[0][x][y].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "456d9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1915602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "197d09ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-d200cee8d115461e8673007b22cc03f7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d200cee8d115461e8673007b22cc03f7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d200cee8d115461e8673007b22cc03f7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ac10fa76400c18dafea2d104267bb03d\"}, \"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"Subsequent Mask\", \"scale\": {\"scheme\": \"viridis\"}}, \"x\": {\"type\": \"ordinal\", \"field\": \"Window\"}, \"y\": {\"type\": \"ordinal\", \"field\": \"Masking\"}}, \"height\": 250, \"selection\": {\"selector004\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 250, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ac10fa76400c18dafea2d104267bb03d\": [{\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 0, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 1, \"Masking\": 0}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 1, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 2, \"Masking\": 1}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 2, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 3, \"Masking\": 2}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 3, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 4, \"Masking\": 3}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 4, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 5, \"Masking\": 4}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 5, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 6, \"Masking\": 5}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 6, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 7, \"Masking\": 6}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 7, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 8, \"Masking\": 7}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 8, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 9, \"Masking\": 8}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 9, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 10, \"Masking\": 9}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 10, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 11, \"Masking\": 10}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 11, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 12, \"Masking\": 11}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 12, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 13, \"Masking\": 12}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 13, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 14, \"Masking\": 13}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 14, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 15, \"Masking\": 14}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 15, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 16, \"Masking\": 15}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 16, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 17, \"Masking\": 16}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 17, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 18, \"Masking\": 17}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 18, \"Masking\": 19}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 0}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 1}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 2}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 3}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 4}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 5}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 6}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 7}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 8}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 9}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 10}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 11}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 12}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 13}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 14}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 15}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 16}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 17}, {\"Subsequent Mask\": false, \"Window\": 19, \"Masking\": 18}, {\"Subsequent Mask\": true, \"Window\": 19, \"Masking\": 19}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_mask():\n",
    "    LS_data = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Subsequent Mask\": subsequent_mask(20)[0][x, y].flatten(),\n",
    "                    \"Window\": y,\n",
    "                    \"Masking\": x,\n",
    "                }\n",
    "            )\n",
    "            for y in range(20)\n",
    "            for x in range(20)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        alt.Chart(LS_data)\n",
    "        .mark_rect()\n",
    "        .properties(height=250, width=250)\n",
    "        .encode(\n",
    "            alt.X(\"Window:O\"),\n",
    "            alt.Y(\"Masking:O\"),\n",
    "            alt.Color(\"Subsequent Mask:Q\", scale=alt.Scale(scheme=\"viridis\")),\n",
    "        )\n",
    "        .interactive()\n",
    "    )\n",
    "\n",
    "\n",
    "show_example(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb19ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22faadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6a4e3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc6f41f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0108, 0.3177, 0.7418, 0.5982],\n",
       "        [0.5857, 0.7359, 0.4902, 0.4367],\n",
       "        [0.8059, 0.4806, 0.8149, 0.3080]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88cf8f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0108, 0.5857, 0.8059],\n",
       "        [0.3177, 0.7359, 0.4806],\n",
       "        [0.7418, 0.4902, 0.8149],\n",
       "        [0.5982, 0.4367, 0.3080]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "30115193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8525af1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4390, 0.0707, 0.4652, 0.1999],\n",
      "         [0.5032, 0.3814, 0.9141, 0.0198],\n",
      "         [0.8172, 0.7814, 0.3147, 0.4379]]])\n",
      "tensor([[[0.9709, 0.1316, 0.9062, 0.5892],\n",
      "         [0.5745, 0.7466, 0.4297, 0.7534],\n",
      "         [0.1304, 0.6124, 0.4037, 0.0398]]])\n",
      "tensor([[[0.2198, 0.0372, 0.4074, 0.2016],\n",
      "         [0.9907, 0.1577, 0.0249, 0.3091],\n",
      "         [0.9093, 0.8080, 0.0172, 0.5201]]])\n"
     ]
    }
   ],
   "source": [
    "d_model = 4\n",
    "m = 3\n",
    "linears = nn.Linear(d_model, d_model)\n",
    "\n",
    "query = torch.rand((1, m, d_model))\n",
    "print(query)\n",
    "\n",
    "key = torch.rand((1, m, d_model))\n",
    "print(key)\n",
    "\n",
    "value = torch.rand((1, m, d_model))\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8a6b92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "09a28fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4, out_features=4, bias=True)\n",
      "tensor([[[0.4390, 0.0707, 0.4652, 0.1999],\n",
      "         [0.5032, 0.3814, 0.9141, 0.0198],\n",
      "         [0.8172, 0.7814, 0.3147, 0.4379]]])\n",
      "Linear(in_features=4, out_features=4, bias=True)\n",
      "tensor([[[0.9709, 0.1316, 0.9062, 0.5892],\n",
      "         [0.5745, 0.7466, 0.4297, 0.7534],\n",
      "         [0.1304, 0.6124, 0.4037, 0.0398]]])\n",
      "Linear(in_features=4, out_features=4, bias=True)\n",
      "tensor([[[0.2198, 0.0372, 0.4074, 0.2016],\n",
      "         [0.9907, 0.1577, 0.0249, 0.3091],\n",
      "         [0.9093, 0.8080, 0.0172, 0.5201]]])\n"
     ]
    }
   ],
   "source": [
    "linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "for lin, x in zip(linears, (query, key, value)):\n",
    "    print(lin)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e0b37b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bd9f104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(query).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "470addb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6419,  0.7506],\n",
       "          [-0.4159,  0.5317]],\n",
       "\n",
       "         [[ 1.0187,  0.6749],\n",
       "          [-0.5196,  0.6189]],\n",
       "\n",
       "         [[ 1.3463,  0.6330],\n",
       "          [-0.5291,  0.5539]]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 2\n",
    "d_k = d_model // h\n",
    "nbatches = query.size(0)\n",
    "lin(x).view(nbatches, -1, h, d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f43edcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 2])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(x).view(nbatches, -1, h, d_k).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "33ec181b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 2])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(x).view(nbatches, -1, h, d_k).transpose(1, 2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6f280033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6419,  0.7506],\n",
       "          [ 1.0187,  0.6749],\n",
       "          [ 1.3463,  0.6330]],\n",
       "\n",
       "         [[-0.4159,  0.5317],\n",
       "          [-0.5196,  0.6189],\n",
       "          [-0.5291,  0.5539]]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(x).view(nbatches, -1, h, d_k).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e87c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "370e20a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 10\n",
    "d_model = 40\n",
    "\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7c60c505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cc1e1410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, max_len).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "498354eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, max_len).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "242f3724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 6.3096e-01, 3.9811e-01, 2.5119e-01, 1.5849e-01, 1.0000e-01,\n",
       "        6.3096e-02, 3.9811e-02, 2.5119e-02, 1.5849e-02, 1.0000e-02, 6.3096e-03,\n",
       "        3.9811e-03, 2.5119e-03, 1.5849e-03, 1.0000e-03, 6.3096e-04, 3.9811e-04,\n",
       "        2.5119e-04, 1.5849e-04])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "div_term = torch.exp(\n",
    "    torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    ")\n",
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dd38c81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
       "        36, 38])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, d_model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "68bfede7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(0, max_len).unsqueeze(1)\n",
    "print(position.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4c565161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0],\n",
       "        [  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
       "          28,  30,  32,  34,  36,  38],\n",
       "        [  0,   4,   8,  12,  16,  20,  24,  28,  32,  36,  40,  44,  48,  52,\n",
       "          56,  60,  64,  68,  72,  76],\n",
       "        [  0,   6,  12,  18,  24,  30,  36,  42,  48,  54,  60,  66,  72,  78,\n",
       "          84,  90,  96, 102, 108, 114],\n",
       "        [  0,   8,  16,  24,  32,  40,  48,  56,  64,  72,  80,  88,  96, 104,\n",
       "         112, 120, 128, 136, 144, 152],\n",
       "        [  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "         140, 150, 160, 170, 180, 190],\n",
       "        [  0,  12,  24,  36,  48,  60,  72,  84,  96, 108, 120, 132, 144, 156,\n",
       "         168, 180, 192, 204, 216, 228],\n",
       "        [  0,  14,  28,  42,  56,  70,  84,  98, 112, 126, 140, 154, 168, 182,\n",
       "         196, 210, 224, 238, 252, 266],\n",
       "        [  0,  16,  32,  48,  64,  80,  96, 112, 128, 144, 160, 176, 192, 208,\n",
       "         224, 240, 256, 272, 288, 304],\n",
       "        [  0,  18,  36,  54,  72,  90, 108, 126, 144, 162, 180, 198, 216, 234,\n",
       "         252, 270, 288, 306, 324, 342]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position * torch.arange(0, d_model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "801cc0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 6.3096e-01, 3.9811e-01, 2.5119e-01, 1.5849e-01, 1.0000e-01,\n",
       "         6.3096e-02, 3.9811e-02, 2.5119e-02, 1.5849e-02, 1.0000e-02, 6.3096e-03,\n",
       "         3.9811e-03, 2.5119e-03, 1.5849e-03, 1.0000e-03, 6.3096e-04, 3.9811e-04,\n",
       "         2.5119e-04, 1.5849e-04],\n",
       "        [2.0000e+00, 1.2619e+00, 7.9621e-01, 5.0238e-01, 3.1698e-01, 2.0000e-01,\n",
       "         1.2619e-01, 7.9621e-02, 5.0238e-02, 3.1698e-02, 2.0000e-02, 1.2619e-02,\n",
       "         7.9621e-03, 5.0238e-03, 3.1698e-03, 2.0000e-03, 1.2619e-03, 7.9621e-04,\n",
       "         5.0238e-04, 3.1698e-04],\n",
       "        [3.0000e+00, 1.8929e+00, 1.1943e+00, 7.5357e-01, 4.7547e-01, 3.0000e-01,\n",
       "         1.8929e-01, 1.1943e-01, 7.5357e-02, 4.7547e-02, 3.0000e-02, 1.8929e-02,\n",
       "         1.1943e-02, 7.5357e-03, 4.7547e-03, 3.0000e-03, 1.8929e-03, 1.1943e-03,\n",
       "         7.5357e-04, 4.7547e-04],\n",
       "        [4.0000e+00, 2.5238e+00, 1.5924e+00, 1.0048e+00, 6.3396e-01, 4.0000e-01,\n",
       "         2.5238e-01, 1.5924e-01, 1.0048e-01, 6.3396e-02, 4.0000e-02, 2.5238e-02,\n",
       "         1.5924e-02, 1.0048e-02, 6.3396e-03, 4.0000e-03, 2.5238e-03, 1.5924e-03,\n",
       "         1.0048e-03, 6.3396e-04],\n",
       "        [5.0000e+00, 3.1548e+00, 1.9905e+00, 1.2559e+00, 7.9245e-01, 5.0000e-01,\n",
       "         3.1548e-01, 1.9905e-01, 1.2559e-01, 7.9245e-02, 5.0000e-02, 3.1548e-02,\n",
       "         1.9905e-02, 1.2559e-02, 7.9245e-03, 5.0000e-03, 3.1548e-03, 1.9905e-03,\n",
       "         1.2559e-03, 7.9245e-04],\n",
       "        [6.0000e+00, 3.7857e+00, 2.3886e+00, 1.5071e+00, 9.5094e-01, 6.0000e-01,\n",
       "         3.7857e-01, 2.3886e-01, 1.5071e-01, 9.5094e-02, 6.0000e-02, 3.7857e-02,\n",
       "         2.3886e-02, 1.5071e-02, 9.5094e-03, 6.0000e-03, 3.7857e-03, 2.3886e-03,\n",
       "         1.5071e-03, 9.5094e-04],\n",
       "        [7.0000e+00, 4.4167e+00, 2.7868e+00, 1.7583e+00, 1.1094e+00, 7.0000e-01,\n",
       "         4.4167e-01, 2.7867e-01, 1.7583e-01, 1.1094e-01, 7.0000e-02, 4.4167e-02,\n",
       "         2.7868e-02, 1.7583e-02, 1.1094e-02, 7.0000e-03, 4.4167e-03, 2.7868e-03,\n",
       "         1.7583e-03, 1.1094e-03],\n",
       "        [8.0000e+00, 5.0477e+00, 3.1849e+00, 2.0095e+00, 1.2679e+00, 8.0000e-01,\n",
       "         5.0477e-01, 3.1849e-01, 2.0095e-01, 1.2679e-01, 8.0000e-02, 5.0477e-02,\n",
       "         3.1849e-02, 2.0095e-02, 1.2679e-02, 8.0000e-03, 5.0477e-03, 3.1849e-03,\n",
       "         2.0095e-03, 1.2679e-03],\n",
       "        [9.0000e+00, 5.6786e+00, 3.5830e+00, 2.2607e+00, 1.4264e+00, 9.0000e-01,\n",
       "         5.6786e-01, 3.5830e-01, 2.2607e-01, 1.4264e-01, 9.0000e-02, 5.6786e-02,\n",
       "         3.5830e-02, 2.2607e-02, 1.4264e-02, 9.0000e-03, 5.6786e-03, 3.5830e-03,\n",
       "         2.2607e-03, 1.4264e-03]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position * div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e0143ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 8.4147e-01,  5.8992e-01,  3.8767e-01,  2.4856e-01,  1.5783e-01,\n",
       "          9.9833e-02,  6.3054e-02,  3.9800e-02,  2.5116e-02,  1.5848e-02,\n",
       "          9.9998e-03,  6.3095e-03,  3.9811e-03,  2.5119e-03,  1.5849e-03,\n",
       "          1.0000e-03,  6.3096e-04,  3.9811e-04,  2.5119e-04,  1.5849e-04],\n",
       "        [ 9.0930e-01,  9.5267e-01,  7.1471e-01,  4.8151e-01,  3.1170e-01,\n",
       "          1.9867e-01,  1.2586e-01,  7.9537e-02,  5.0217e-02,  3.1693e-02,\n",
       "          1.9999e-02,  1.2619e-02,  7.9621e-03,  5.0238e-03,  3.1698e-03,\n",
       "          2.0000e-03,  1.2619e-03,  7.9621e-04,  5.0238e-04,  3.1698e-04],\n",
       "        [ 1.4112e-01,  9.4858e-01,  9.2997e-01,  6.8424e-01,  4.5775e-01,\n",
       "          2.9552e-01,  1.8816e-01,  1.1915e-01,  7.5285e-02,  4.7529e-02,\n",
       "          2.9995e-02,  1.8928e-02,  1.1943e-02,  7.5356e-03,  4.7547e-03,\n",
       "          3.0000e-03,  1.8929e-03,  1.1943e-03,  7.5357e-04,  4.7547e-04],\n",
       "        [-7.5680e-01,  5.7921e-01,  9.9977e-01,  8.4403e-01,  5.9234e-01,\n",
       "          3.8942e-01,  2.4971e-01,  1.5857e-01,  1.0031e-01,  6.3353e-02,\n",
       "          3.9989e-02,  2.5236e-02,  1.5924e-02,  1.0047e-02,  6.3395e-03,\n",
       "          4.0000e-03,  2.5238e-03,  1.5924e-03,  1.0048e-03,  6.3396e-04],\n",
       "        [-9.5892e-01, -1.3194e-02,  9.1320e-01,  9.5084e-01,  7.1207e-01,\n",
       "          4.7943e-01,  3.1027e-01,  1.9774e-01,  1.2526e-01,  7.9162e-02,\n",
       "          4.9979e-02,  3.1543e-02,  1.9904e-02,  1.2559e-02,  7.9244e-03,\n",
       "          5.0000e-03,  3.1548e-03,  1.9905e-03,  1.2559e-03,  7.9245e-04],\n",
       "        [-2.7942e-01, -6.0052e-01,  6.8379e-01,  9.9797e-01,  8.1396e-01,\n",
       "          5.6464e-01,  3.6960e-01,  2.3660e-01,  1.5014e-01,  9.4950e-02,\n",
       "          5.9964e-02,  3.7848e-02,  2.3884e-02,  1.5071e-02,  9.5092e-03,\n",
       "          6.0000e-03,  3.7857e-03,  2.3886e-03,  1.5071e-03,  9.5094e-04],\n",
       "        [ 6.5699e-01, -9.5660e-01,  3.4744e-01,  9.8247e-01,  8.9544e-01,\n",
       "          6.4422e-01,  4.2745e-01,  2.7508e-01,  1.7493e-01,  1.1072e-01,\n",
       "          6.9943e-02,  4.4153e-02,  2.7864e-02,  1.7582e-02,  1.1094e-02,\n",
       "          6.9999e-03,  4.4167e-03,  2.7867e-03,  1.7583e-03,  1.1094e-03],\n",
       "        [ 9.8936e-01, -9.4432e-01, -4.3251e-02,  9.0530e-01,  9.5448e-01,\n",
       "          7.1736e-01,  4.8360e-01,  3.1313e-01,  1.9960e-01,  1.2645e-01,\n",
       "          7.9915e-02,  5.0455e-02,  3.1843e-02,  2.0094e-02,  1.2679e-02,\n",
       "          7.9999e-03,  5.0476e-03,  3.1849e-03,  2.0095e-03,  1.2679e-03],\n",
       "        [ 4.1212e-01, -5.6841e-01, -4.2718e-01,  7.7131e-01,  9.8959e-01,\n",
       "          7.8333e-01,  5.3783e-01,  3.5068e-01,  2.2415e-01,  1.4216e-01,\n",
       "          8.9879e-02,  5.6756e-02,  3.5822e-02,  2.2605e-02,  1.4264e-02,\n",
       "          8.9999e-03,  5.6786e-03,  3.5830e-03,  2.2607e-03,  1.4264e-03]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(position * div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9a6769c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sin(position * div_term).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6cc9b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cc8fb496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 8.4147e-01,  5.8992e-01,  3.8767e-01,  2.4856e-01,  1.5783e-01,\n",
       "          9.9833e-02,  6.3054e-02,  3.9800e-02,  2.5116e-02,  1.5848e-02,\n",
       "          9.9998e-03,  6.3095e-03,  3.9811e-03,  2.5119e-03,  1.5849e-03,\n",
       "          1.0000e-03,  6.3096e-04,  3.9811e-04,  2.5119e-04,  1.5849e-04],\n",
       "        [ 9.0930e-01,  9.5267e-01,  7.1471e-01,  4.8151e-01,  3.1170e-01,\n",
       "          1.9867e-01,  1.2586e-01,  7.9537e-02,  5.0217e-02,  3.1693e-02,\n",
       "          1.9999e-02,  1.2619e-02,  7.9621e-03,  5.0238e-03,  3.1698e-03,\n",
       "          2.0000e-03,  1.2619e-03,  7.9621e-04,  5.0238e-04,  3.1698e-04],\n",
       "        [ 1.4112e-01,  9.4858e-01,  9.2997e-01,  6.8424e-01,  4.5775e-01,\n",
       "          2.9552e-01,  1.8816e-01,  1.1915e-01,  7.5285e-02,  4.7529e-02,\n",
       "          2.9995e-02,  1.8928e-02,  1.1943e-02,  7.5356e-03,  4.7547e-03,\n",
       "          3.0000e-03,  1.8929e-03,  1.1943e-03,  7.5357e-04,  4.7547e-04],\n",
       "        [-7.5680e-01,  5.7921e-01,  9.9977e-01,  8.4403e-01,  5.9234e-01,\n",
       "          3.8942e-01,  2.4971e-01,  1.5857e-01,  1.0031e-01,  6.3353e-02,\n",
       "          3.9989e-02,  2.5236e-02,  1.5924e-02,  1.0047e-02,  6.3395e-03,\n",
       "          4.0000e-03,  2.5238e-03,  1.5924e-03,  1.0048e-03,  6.3396e-04],\n",
       "        [-9.5892e-01, -1.3194e-02,  9.1320e-01,  9.5084e-01,  7.1207e-01,\n",
       "          4.7943e-01,  3.1027e-01,  1.9774e-01,  1.2526e-01,  7.9162e-02,\n",
       "          4.9979e-02,  3.1543e-02,  1.9904e-02,  1.2559e-02,  7.9244e-03,\n",
       "          5.0000e-03,  3.1548e-03,  1.9905e-03,  1.2559e-03,  7.9245e-04],\n",
       "        [-2.7942e-01, -6.0052e-01,  6.8379e-01,  9.9797e-01,  8.1396e-01,\n",
       "          5.6464e-01,  3.6960e-01,  2.3660e-01,  1.5014e-01,  9.4950e-02,\n",
       "          5.9964e-02,  3.7848e-02,  2.3884e-02,  1.5071e-02,  9.5092e-03,\n",
       "          6.0000e-03,  3.7857e-03,  2.3886e-03,  1.5071e-03,  9.5094e-04],\n",
       "        [ 6.5699e-01, -9.5660e-01,  3.4744e-01,  9.8247e-01,  8.9544e-01,\n",
       "          6.4422e-01,  4.2745e-01,  2.7508e-01,  1.7493e-01,  1.1072e-01,\n",
       "          6.9943e-02,  4.4153e-02,  2.7864e-02,  1.7582e-02,  1.1094e-02,\n",
       "          6.9999e-03,  4.4167e-03,  2.7867e-03,  1.7583e-03,  1.1094e-03],\n",
       "        [ 9.8936e-01, -9.4432e-01, -4.3251e-02,  9.0530e-01,  9.5448e-01,\n",
       "          7.1736e-01,  4.8360e-01,  3.1313e-01,  1.9960e-01,  1.2645e-01,\n",
       "          7.9915e-02,  5.0455e-02,  3.1843e-02,  2.0094e-02,  1.2679e-02,\n",
       "          7.9999e-03,  5.0476e-03,  3.1849e-03,  2.0095e-03,  1.2679e-03],\n",
       "        [ 4.1212e-01, -5.6841e-01, -4.2718e-01,  7.7131e-01,  9.8959e-01,\n",
       "          7.8333e-01,  5.3783e-01,  3.5068e-01,  2.2415e-01,  1.4216e-01,\n",
       "          8.9879e-02,  5.6756e-02,  3.5822e-02,  2.2605e-02,  1.4264e-02,\n",
       "          8.9999e-03,  5.6786e-03,  3.5830e-03,  2.2607e-03,  1.4264e-03]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, 0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a27c8a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 8.4147e-01,  0.0000e+00,  5.8992e-01,  0.0000e+00,  3.8767e-01,\n",
       "          0.0000e+00,  2.4856e-01,  0.0000e+00,  1.5783e-01,  0.0000e+00,\n",
       "          9.9833e-02,  0.0000e+00,  6.3054e-02,  0.0000e+00,  3.9800e-02,\n",
       "          0.0000e+00,  2.5116e-02,  0.0000e+00,  1.5848e-02,  0.0000e+00,\n",
       "          9.9998e-03,  0.0000e+00,  6.3095e-03,  0.0000e+00,  3.9811e-03,\n",
       "          0.0000e+00,  2.5119e-03,  0.0000e+00,  1.5849e-03,  0.0000e+00,\n",
       "          1.0000e-03,  0.0000e+00,  6.3096e-04,  0.0000e+00,  3.9811e-04,\n",
       "          0.0000e+00,  2.5119e-04,  0.0000e+00,  1.5849e-04,  0.0000e+00],\n",
       "        [ 9.0930e-01,  0.0000e+00,  9.5267e-01,  0.0000e+00,  7.1471e-01,\n",
       "          0.0000e+00,  4.8151e-01,  0.0000e+00,  3.1170e-01,  0.0000e+00,\n",
       "          1.9867e-01,  0.0000e+00,  1.2586e-01,  0.0000e+00,  7.9537e-02,\n",
       "          0.0000e+00,  5.0217e-02,  0.0000e+00,  3.1693e-02,  0.0000e+00,\n",
       "          1.9999e-02,  0.0000e+00,  1.2619e-02,  0.0000e+00,  7.9621e-03,\n",
       "          0.0000e+00,  5.0238e-03,  0.0000e+00,  3.1698e-03,  0.0000e+00,\n",
       "          2.0000e-03,  0.0000e+00,  1.2619e-03,  0.0000e+00,  7.9621e-04,\n",
       "          0.0000e+00,  5.0238e-04,  0.0000e+00,  3.1698e-04,  0.0000e+00],\n",
       "        [ 1.4112e-01,  0.0000e+00,  9.4858e-01,  0.0000e+00,  9.2997e-01,\n",
       "          0.0000e+00,  6.8424e-01,  0.0000e+00,  4.5775e-01,  0.0000e+00,\n",
       "          2.9552e-01,  0.0000e+00,  1.8816e-01,  0.0000e+00,  1.1915e-01,\n",
       "          0.0000e+00,  7.5285e-02,  0.0000e+00,  4.7529e-02,  0.0000e+00,\n",
       "          2.9995e-02,  0.0000e+00,  1.8928e-02,  0.0000e+00,  1.1943e-02,\n",
       "          0.0000e+00,  7.5356e-03,  0.0000e+00,  4.7547e-03,  0.0000e+00,\n",
       "          3.0000e-03,  0.0000e+00,  1.8929e-03,  0.0000e+00,  1.1943e-03,\n",
       "          0.0000e+00,  7.5357e-04,  0.0000e+00,  4.7547e-04,  0.0000e+00],\n",
       "        [-7.5680e-01,  0.0000e+00,  5.7921e-01,  0.0000e+00,  9.9977e-01,\n",
       "          0.0000e+00,  8.4403e-01,  0.0000e+00,  5.9234e-01,  0.0000e+00,\n",
       "          3.8942e-01,  0.0000e+00,  2.4971e-01,  0.0000e+00,  1.5857e-01,\n",
       "          0.0000e+00,  1.0031e-01,  0.0000e+00,  6.3353e-02,  0.0000e+00,\n",
       "          3.9989e-02,  0.0000e+00,  2.5236e-02,  0.0000e+00,  1.5924e-02,\n",
       "          0.0000e+00,  1.0047e-02,  0.0000e+00,  6.3395e-03,  0.0000e+00,\n",
       "          4.0000e-03,  0.0000e+00,  2.5238e-03,  0.0000e+00,  1.5924e-03,\n",
       "          0.0000e+00,  1.0048e-03,  0.0000e+00,  6.3396e-04,  0.0000e+00],\n",
       "        [-9.5892e-01,  0.0000e+00, -1.3194e-02,  0.0000e+00,  9.1320e-01,\n",
       "          0.0000e+00,  9.5084e-01,  0.0000e+00,  7.1207e-01,  0.0000e+00,\n",
       "          4.7943e-01,  0.0000e+00,  3.1027e-01,  0.0000e+00,  1.9774e-01,\n",
       "          0.0000e+00,  1.2526e-01,  0.0000e+00,  7.9162e-02,  0.0000e+00,\n",
       "          4.9979e-02,  0.0000e+00,  3.1543e-02,  0.0000e+00,  1.9904e-02,\n",
       "          0.0000e+00,  1.2559e-02,  0.0000e+00,  7.9244e-03,  0.0000e+00,\n",
       "          5.0000e-03,  0.0000e+00,  3.1548e-03,  0.0000e+00,  1.9905e-03,\n",
       "          0.0000e+00,  1.2559e-03,  0.0000e+00,  7.9245e-04,  0.0000e+00],\n",
       "        [-2.7942e-01,  0.0000e+00, -6.0052e-01,  0.0000e+00,  6.8379e-01,\n",
       "          0.0000e+00,  9.9797e-01,  0.0000e+00,  8.1396e-01,  0.0000e+00,\n",
       "          5.6464e-01,  0.0000e+00,  3.6960e-01,  0.0000e+00,  2.3660e-01,\n",
       "          0.0000e+00,  1.5014e-01,  0.0000e+00,  9.4950e-02,  0.0000e+00,\n",
       "          5.9964e-02,  0.0000e+00,  3.7848e-02,  0.0000e+00,  2.3884e-02,\n",
       "          0.0000e+00,  1.5071e-02,  0.0000e+00,  9.5092e-03,  0.0000e+00,\n",
       "          6.0000e-03,  0.0000e+00,  3.7857e-03,  0.0000e+00,  2.3886e-03,\n",
       "          0.0000e+00,  1.5071e-03,  0.0000e+00,  9.5094e-04,  0.0000e+00],\n",
       "        [ 6.5699e-01,  0.0000e+00, -9.5660e-01,  0.0000e+00,  3.4744e-01,\n",
       "          0.0000e+00,  9.8247e-01,  0.0000e+00,  8.9544e-01,  0.0000e+00,\n",
       "          6.4422e-01,  0.0000e+00,  4.2745e-01,  0.0000e+00,  2.7508e-01,\n",
       "          0.0000e+00,  1.7493e-01,  0.0000e+00,  1.1072e-01,  0.0000e+00,\n",
       "          6.9943e-02,  0.0000e+00,  4.4153e-02,  0.0000e+00,  2.7864e-02,\n",
       "          0.0000e+00,  1.7582e-02,  0.0000e+00,  1.1094e-02,  0.0000e+00,\n",
       "          6.9999e-03,  0.0000e+00,  4.4167e-03,  0.0000e+00,  2.7867e-03,\n",
       "          0.0000e+00,  1.7583e-03,  0.0000e+00,  1.1094e-03,  0.0000e+00],\n",
       "        [ 9.8936e-01,  0.0000e+00, -9.4432e-01,  0.0000e+00, -4.3251e-02,\n",
       "          0.0000e+00,  9.0530e-01,  0.0000e+00,  9.5448e-01,  0.0000e+00,\n",
       "          7.1736e-01,  0.0000e+00,  4.8360e-01,  0.0000e+00,  3.1313e-01,\n",
       "          0.0000e+00,  1.9960e-01,  0.0000e+00,  1.2645e-01,  0.0000e+00,\n",
       "          7.9915e-02,  0.0000e+00,  5.0455e-02,  0.0000e+00,  3.1843e-02,\n",
       "          0.0000e+00,  2.0094e-02,  0.0000e+00,  1.2679e-02,  0.0000e+00,\n",
       "          7.9999e-03,  0.0000e+00,  5.0476e-03,  0.0000e+00,  3.1849e-03,\n",
       "          0.0000e+00,  2.0095e-03,  0.0000e+00,  1.2679e-03,  0.0000e+00],\n",
       "        [ 4.1212e-01,  0.0000e+00, -5.6841e-01,  0.0000e+00, -4.2718e-01,\n",
       "          0.0000e+00,  7.7131e-01,  0.0000e+00,  9.8959e-01,  0.0000e+00,\n",
       "          7.8333e-01,  0.0000e+00,  5.3783e-01,  0.0000e+00,  3.5068e-01,\n",
       "          0.0000e+00,  2.2415e-01,  0.0000e+00,  1.4216e-01,  0.0000e+00,\n",
       "          8.9879e-02,  0.0000e+00,  5.6756e-02,  0.0000e+00,  3.5822e-02,\n",
       "          0.0000e+00,  2.2605e-02,  0.0000e+00,  1.4264e-02,  0.0000e+00,\n",
       "          8.9999e-03,  0.0000e+00,  5.6786e-03,  0.0000e+00,  3.5830e-03,\n",
       "          0.0000e+00,  2.2607e-03,  0.0000e+00,  1.4264e-03,  0.0000e+00]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc65920",
   "metadata": {},
   "source": [
    "## BERT\n",
    "\n",
    "This section is based on [original BERT Paper](https://arxiv.org/abs/1810.04805). Here is the [Github for the original BERT paper](https://github.com/google-research/bert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8daa45",
   "metadata": {},
   "source": [
    "## All The Ways You Can Compress BERT\n",
    "\n",
    "This section is based on the [work by Mitchell G. Gordon](https://mitchgordon.me/machine/learning/2019/11/18/all-the-ways-to-compress-BERT.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474f6a5",
   "metadata": {},
   "source": [
    "## Literature Review\n",
    "\n",
    "Remember to submit lit-review by **03-10** and apply penalty waiver for late submission.\n",
    "\n",
    "\n",
    "### Reading list:\n",
    "1. [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)\n",
    "2. [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108)\n",
    "3. [MobileBERT: Task-Agnostic Compression of BERT by Progressive Knowledge Transfer](https://arxiv.org/abs/2004.02984)\n",
    "4. [Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT](https://arxiv.org/abs/1909.05840)\n",
    "5. [Reducing Transformer Depth on Demand with Structured Dropout](https://arxiv.org/pdf/1909.11556.pdf)\n",
    "6. [GLUE: A MULTI-TASK BENCHMARK AND ANALYSIS PLATFORM FOR NATURAL LANGUAGE UNDERSTANDING](https://openreview.net/pdf?id=rJ4km2R5t7)\n",
    "7. [The Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)\n",
    "8. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "9. [WELL-READ STUDENTS LEARN BETTER: ON THE IMPORTANCE OF PRE-TRAINING COMPACT MODELS](https://arxiv.org/pdf/1908.08962.pdf)\n",
    "10. MNLI Paper\n",
    "\n",
    "### Submission\n",
    "[My Literature Review](https://docs.google.com/document/d/101v9k7yc5brOkMI_MOUL7h28HKIlp6Ir3DAokwcxa3k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c48722",
   "metadata": {},
   "source": [
    "## Schedule:\n",
    "- ~**03/06**: 2 papers~  \n",
    "- ~**03/07**: 2 papers~  \n",
    "- ~**03/08**: 2 papers~  \n",
    "- ~**03/09**: write lit-review~\n",
    "- ~**03/10**: submit lit-review~ \n",
    "- ~**03/11**: experiment~\n",
    "- ~**03/13**: experiment~\n",
    "- ~**03/14**: experiment _Hypothesis, Dataset, Metrics_~\n",
    "- ~**03/15**: experiment _Models, general reasoning_~\n",
    "- ~**03/16**: experiment _Models, general reasoning_~\n",
    "- ~**03/17**: experiment _Metrics, Models, general reasoning_~\n",
    "- ~**03/18**: experiment _Models, general reasoning_~\n",
    "- ~**03/19**: experiment _Models, general reasoning_~\n",
    "- ~**03/20**: experiment and submit (*XCS330 1st day!*)~\n",
    "- ~**03/21**: paper~\n",
    "- ~**03/22**: paper~\n",
    "- ~**03/23**: paper~\n",
    "- ~**03/24**: paper~\n",
    "- **03/25**: paper\n",
    "- **03/27**: paper\n",
    "- **03/28**: paper\n",
    "- **03/29**: paper\n",
    "- **03/30**: paper\n",
    "- **03/31**: paper\n",
    "- **04/01**: submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d689747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "224u-proj",
   "language": "python",
   "name": "224u-proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
